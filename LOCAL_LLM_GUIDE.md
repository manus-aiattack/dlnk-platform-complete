# ü§ñ Local LLM Guide - dLNk dLNk Framework

## ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ Mixtral ‡πÅ‡∏•‡πâ‡∏ß! ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢

### ‚úÖ Quick Start

```bash
# 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Ollama
ollama list

# 2. ‡∏£‡∏±‡∏ô Ollama server (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ô)
ollama serve

# 3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI System
python3 dlnk_ai_system_local.py
```

### üìã Configuration

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå `llm_config.py`:

```python
# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Provider
LLM_PROVIDER = "ollama"  # ‡∏´‡∏£‡∏∑‡∏≠ "openai", "lmstudio", "localai"

# Ollama Settings
OLLAMA_BASE_URL = "http://localhost:11434/v1"
OLLAMA_MODEL = "mixtral:latest"  # ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ model ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß!
```

### üéØ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AI System

#### 1. Attack Planning

```python
from dlnk_ai_system_local import dLNkAISystem

ai = dLNkAISystem()

result = ai.generate_attack_plan({
    "target": "https://target.com",
    "type": "Web Application",
    "technology": "PHP + MySQL"
})

print(result['content'])
```

#### 2. Vulnerability Analysis

```python
result = ai.analyze_vulnerability({
    "type": "SQL Injection",
    "details": "Parameter 'id' vulnerable",
    "severity": "Critical"
})

print(result['content'])
```

#### 3. Report Generation

```python
result = ai.generate_report({
    "vulnerabilities": [...],
    "exploits": [...],
    "findings": [...]
})

print(result['content'])
```

### üîß ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô LLM Provider

#### ‡πÉ‡∏ä‡πâ OpenAI

```python
# llm_config.py
LLM_PROVIDER = "openai"
OPENAI_API_KEY = "sk-..."
OPENAI_MODEL = "gpt-4.1-mini"
```

```bash
export OPENAI_API_KEY="sk-..."
python3 dlnk_ai_system_local.py
```

#### ‡πÉ‡∏ä‡πâ LM Studio

```python
# llm_config.py
LLM_PROVIDER = "lmstudio"
LMSTUDIO_BASE_URL = "http://localhost:1234/v1"
```

#### ‡πÉ‡∏ä‡πâ LocalAI

```python
# llm_config.py
LLM_PROVIDER = "localai"
LOCALAI_BASE_URL = "http://localhost:8080/v1"
```

### üìä Models ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Offensive Security

#### Ollama Models

```bash
# Code & Security focused
ollama pull codellama:34b
ollama pull deepseek-coder:33b

# General purpose (good for Thai)
ollama pull mixtral:latest  # ‚úÖ ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡πÅ‡∏•‡πâ‡∏ß!
ollama pull llama3.2:latest

# Lightweight
ollama pull mistral:latest
ollama pull phi3:latest
```

#### Model Comparison

| Model | Size | Speed | Quality | Thai Support |
|-------|------|-------|---------|--------------|
| **mixtral:latest** | 26GB | Medium | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| codellama:34b | 19GB | Medium | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| llama3.2:latest | 4.7GB | Fast | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| mistral:latest | 4.1GB | Fast | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |

### üöÄ Performance Tips

#### 1. GPU Acceleration

```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
nvidia-smi

# Ollama ‡∏à‡∏∞‡πÉ‡∏ä‡πâ GPU ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
```

#### 2. Adjust Temperature

```python
# llm_config.py
TEMPERATURE = 0.7  # ‡∏™‡∏π‡∏á = creative, ‡∏ï‡πà‡∏≥ = precise
```

#### 3. Adjust Max Tokens

```python
# llm_config.py
MAX_TOKENS = 4000  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏¢‡∏≤‡∏ß
```

### üîç Troubleshooting

#### Ollama ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö service
ps aux | grep ollama

# ‡∏£‡∏±‡∏ô Ollama
ollama serve

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
curl http://localhost:11434/api/tags
```

#### Model ‡∏ä‡πâ‡∏≤

```bash
# ‡∏•‡∏î context window
ollama run mixtral:latest --num-ctx 2048

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ model ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤
ollama pull mistral:latest
```

#### Out of Memory

```bash
# ‡πÉ‡∏ä‡πâ quantized version
ollama pull mixtral:8x7b-instruct-v0.1-q4_0

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ model ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤
ollama pull llama3.2:latest
```

### üìö Integration with Framework

#### ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Agents

```python
# agents/your_agent.py
from dlnk_ai_system_local import dLNkAISystem

class YourAgent(BaseAgent):
    def __init__(self):
        super().__init__()
        self.ai = dLNkAISystem()
    
    async def execute(self, directive, context):
        # ‡πÉ‡∏ä‡πâ AI ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô
        plan = self.ai.generate_attack_plan(context)
        
        # Execute based on plan
        ...
```

#### ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Workflows

```yaml
# workflows/ai_powered_attack.yaml
phases:
  - name: "AI Planning"
    agents:
      - name: "ai_planner"
        directive: "Generate attack plan using AI"
  
  - name: "Execute Plan"
    agents:
      - name: "executor"
        directive: "Execute AI-generated plan"
```

### üéØ Best Practices

1. **‡πÉ‡∏ä‡πâ Mixtral ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö complex tasks** - ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡πÅ‡∏•‡πâ‡∏ß!
2. **‡πÉ‡∏ä‡πâ Mistral ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö simple tasks** - ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤
3. **Cache responses** - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤
4. **Validate AI output** - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ
5. **Monitor performance** - ‡∏î‡∏π response time

### üìñ Examples

#### Example 1: Reconnaissance Planning

```python
ai = dLNkAISystem()

result = ai.generate_attack_plan({
    "target": "https://localhost:8000",
    "type": "Web Application",
    "technology": "React + Node.js + MongoDB"
})

# ‡πÑ‡∏î‡πâ plan ‡∏Ñ‡∏£‡∏ö 3 phases
# - Reconnaissance
# - Exploitation  
# - Post-Exploitation
```

#### Example 2: Exploit Generation

```python
result = ai.analyze_vulnerability({
    "type": "IDOR",
    "details": "User ID in API endpoint not validated",
    "severity": "High"
})

# ‡πÑ‡∏î‡πâ exploit method + payload
```

#### Example 3: Report Writing

```python
result = ai.generate_report({
    "target": "localhost:8000",
    "vulnerabilities": [
        {"type": "SQL Injection", "severity": "Critical"},
        {"type": "XSS", "severity": "Medium"}
    ],
    "findings": "..."
})

# ‡πÑ‡∏î‡πâ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
```

### ‚úÖ Summary

**‡∏Ñ‡∏∏‡∏ì‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Local LLM ‡πÅ‡∏•‡πâ‡∏ß!**

- ‚úÖ Mixtral installed (26GB)
- ‚úÖ Configuration ready
- ‚úÖ AI System ready
- ‚úÖ Examples provided

**‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**

```bash
python3 dlnk_ai_system_local.py
```

---

**Powered by dLNk Framework** üåà

**Made with ‚ù§Ô∏è for Offensive Security**

