"""
Exploit Success Predictor using XGBoost
"""

import asyncio
import numpy as np
from typing import List, Dict
import logging

log = logging.getLogger(__name__)

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    log.warning("[ExploitPredictor] XGBoost not available")


class ExploitPredictor:
    """ML-based exploit success predictor"""
    
    def __init__(self):
        self.model = None
        self.is_trained = False
        
        if XGBOOST_AVAILABLE:
            self.model = xgb.XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
    
    async def train(self, features: List[List[float]], labels: List[int]):
        """Train the predictor"""
        if not XGBOOST_AVAILABLE:
            log.warning("[ExploitPredictor] Training skipped - XGBoost not available")
            return
        
        log.info(f"[ExploitPredictor] Training on {len(features)} samples")
        
        # Train model
        self.model.fit(features, labels)
        self.is_trained = True
        
        log.info("[ExploitPredictor] Training complete")
    
    async def predict_success(self, features: List[float]) -> Dict:
        """Predict exploit success probability"""
        if not XGBOOST_AVAILABLE or not self.is_trained:
            return await self._fallback_predict(features)
        
        # Predict
        features_array = np.array([features])
        prediction = self.model.predict(features_array)[0]
        probability = self.model.predict_proba(features_array)[0]
        
        success_prob = float(probability[1]) if len(probability) > 1 else 0.5
        
        return {
            'will_succeed': bool(prediction),
            'success_probability': success_prob,
            'confidence': max(float(probability[0]), success_prob)
        }
    
    async def _fallback_predict(self, features: List[float]) -> Dict:
        """Fallback prediction without XGBoost"""
        # Simple heuristic
        avg_feature = sum(features) / len(features) if features else 0.5
        success_prob = min(max(avg_feature, 0.0), 1.0)
        
        return {
            'will_succeed': success_prob > 0.5,
            'success_probability': success_prob,
            'confidence': 0.6
        }
