from typing import List
import asyncio
import re
from core.data_models import VulnerabilityReport, Strategy, AttackPhase, ErrorType
from core.nvd_client import NVDClient
from core.github_client import GitHubClient
from core.exploitdb_client import ExploitDBClient
from core.logger import log
from core.cache_manager import CacheManager
from config import settings
import time

from core.base_agent import BaseAgent
from typing import Optional


class VulnerabilityResearcher(BaseAgent):
    supported_phases = [AttackPhase.INITIAL_FOOTHOLD]
    required_tools = []

    def __init__(self, context_manager=None, orchestrator=None, **kwargs):
        super().__init__(context_manager, orchestrator, **kwargs)
        self.nvd_client: Optional[NVDClient] = None
        self.github_client: Optional[GitHubClient] = None
        self.exploitdb_client: Optional[ExploitDBClient] = None
        self.cache_manager: Optional[CacheManager] = None
        self.report_class = VulnerabilityReport

    async def setup(self):
        """Asynchronous setup method for VulnerabilityResearcher."""
        self.nvd_client = await self.context_manager.get_context('nvd_client')
        self.github_client = await self.context_manager.get_context('github_client')
        self.exploitdb_client = await self.context_manager.get_context('exploitdb_client')
        self.cache_manager = await self.context_manager.get_context('cache_manager')

    async def _generate_enhanced_queries(self, initial_queries: List[str], hostname: str) -> List[str]:
        """
        Enhances search queries by adding versions and diverse keywords based on the target model.
        """
        target_model = self.orchestrator.target_model_manager.get_target(
            hostname)
        if not target_model:
            return initial_queries

        enhanced_queries = set(initial_queries)
        diverse_keywords = ["exploit", "vulnerability", "PoC",
                            "misconfiguration", "default credentials", "bypass"]

        for tech_string in target_model.technologies:
            # Simple parsing for name and version (e.g., "Apache httpd 2.4.49")
            parts = tech_string.split()
            if not parts:
                continue

            # Assume the first part is the main tech name, the rest could be part of the name or version
            tech_name_parts = []
            version_parts = []
            found_version = False
            for part in parts:
                if re.match(r'^[\d.]+', part):
                    found_version = True
                if found_version:
                    version_parts.append(part)
                else:
                    tech_name_parts.append(part)

            tech_name = " ".join(tech_name_parts)

            # Add queries for the full version string
            if version_parts:
                full_version = " ".join(version_parts)
                full_tech_name = f"{tech_name} {full_version}"
                for keyword in diverse_keywords:
                    enhanced_queries.add(f'"{full_tech_name}" {keyword}')

                # Add queries for major/minor version (e.g., "Apache 2.4")
                if '.' in full_version:
                    major_minor_version = ".".join(full_version.split('.')[:2])
                    major_minor_tech_name = f"{tech_name} {major_minor_version}"
                    for keyword in diverse_keywords:
                        enhanced_queries.add(
                            f'"{major_minor_tech_name}" {keyword}')

            # Add queries for just the tech name
            for keyword in diverse_keywords:
                enhanced_queries.add(f'"{tech_name}" {keyword}')

        # Also add initial queries with more keywords
        for query in initial_queries:
            for keyword in diverse_keywords:
                enhanced_queries.add(f'{query} {keyword}')

        return list(enhanced_queries)

    async def run(self, strategy: Strategy, **kwargs) -> VulnerabilityReport:
        start_time = time.time()
        initial_queries = strategy.context.get("search_queries", [])
        hostname = strategy.context.get("hostname")
        if not hostname:
            hostname = await self.context_manager.get_context('target_host')

        if not initial_queries and not hostname:
            summary = "No search queries or hostname provided."
            log.warning(summary)
            end_time = time.time()
            return VulnerabilityReport(
                agent_name=self.__class__.__name__,
                start_time=start_time,
                end_time=end_time,
                summary=summary,
                findings=[],
                errors=[summary],
                error_type=ErrorType.CONFIGURATION
            )

        # Generate a cache key based on queries and hostname
        cache_key_parts = sorted(list(set(initial_queries))) + [hostname]
        cache_key = "vulnerability_researcher:" + "_".join(cache_key_parts).replace(" ", "_").replace(":", "_")

        # Check cache first
        cached_report_data = self.cache_manager.get(cache_key)
        if cached_report_data:
            log.info(f"Vulnerability Researcher: Cache hit for {hostname}. Returning cached report.")
            end_time = time.time()
            return VulnerabilityReport(
                agent_name=self.__class__.__name__,
                start_time=start_time,
                end_time=end_time,
                **cached_report_data
            )

        # Generate enhanced queries
        queries = await self._generate_enhanced_queries(initial_queries, hostname)

        if not queries:
            summary = "No search queries could be generated."
            log.warning(summary)
            end_time = time.time()
            return VulnerabilityReport(
                agent_name=self.__class__.__name__,
                start_time=start_time,
                end_time=end_time,
                summary=summary,
                findings=[],
                errors=[summary],
                error_type=ErrorType.LOGIC
            )

        log.info(
            f"Vulnerability Researcher: Starting concurrent research for {len(queries)} queries...")
        log.debug(f"Queries (sample): {queries[:10]}")

        # --- Create concurrent tasks for all searches ---
        nvd_tasks = [self.nvd_client.search_by_keyword(q) for q in queries]
        github_tasks = [self.github_client.search_exploits(q) for q in queries]
        exploitdb_tasks = [self.exploitdb_client.search(q) for q in queries]

        all_tasks = nvd_tasks + github_tasks + exploitdb_tasks
        results = await asyncio.gather(*all_tasks, return_exceptions=True)

        # --- Process results ---
        nvd_results = [r for r in results[:len(
            nvd_tasks)] if r and not isinstance(r, Exception)]
        github_results = [r for r in results[len(
            nvd_tasks):len(nvd_tasks) + len(github_tasks)] if r and not isinstance(r, Exception)]
        exploitdb_results = [r for r in results[len(
            nvd_tasks) + len(github_tasks):] if r and not isinstance(r, Exception)]

        nvd_findings = [item for sublist in nvd_results for item in sublist]
        github_findings = [
            item for sublist in github_results for item in sublist]
        exploitdb_findings = [
            item for sublist in exploitdb_results for item in sublist]

        packetstorm_findings = []

        # --- Analyze, Correlate, and Summarize ---
        if not nvd_findings and not github_findings and not exploitdb_findings and not packetstorm_findings:
            summary = "No vulnerabilities or exploits found."
            log.warning(summary)
            end_time = time.time()
            report = VulnerabilityReport(
                agent_name=self.__class__.__name__,
                start_time=start_time,
                end_time=end_time,
                summary=summary,
                findings=[],
                errors=[summary],
                error_type=ErrorType.NO_VULNERABILITY_FOUND
            )
        else:
            summary, recommended_exploit = self._create_summary(
                nvd_findings, github_findings, exploitdb_findings, packetstorm_findings)
            log.success(summary)

            all_findings = []
            if nvd_findings:
                all_findings.extend([{"source": "NVD", "data": f}
                                    for f in nvd_findings])
            if github_findings:
                all_findings.extend([{"source": "GitHub", "data": f}
                                    for f in github_findings])
            if exploitdb_findings:
                all_findings.extend([{"source": "Exploit-DB", "data": f}
                                    for f in exploitdb_findings])

            end_time = time.time()
            report = VulnerabilityReport(
                agent_name=self.__class__.__name__,
                start_time=start_time,
                end_time=end_time,
                summary=summary, findings=all_findings)
            if recommended_exploit:
                report.summary += f"\nRecommended Exploit URL: {recommended_exploit.get('html_url')}"
        
        # Store report in cache
        self.cache_manager.set(cache_key, report.to_dict(), ttl=settings.REPORT_MAX_AGE_DAYS * 24 * 3600)

        return report

    def _create_summary(self, nvd_findings: List[dict], github_findings: List[dict],
                        exploitdb_findings: List[dict], packetstorm_findings: List[dict]) -> (str, dict):
        """Creates a text summary and identifies the best exploit."""
        best_exploit = None
        summary_parts = []

        if nvd_findings:
            summary_parts.append(f"Found {len(nvd_findings)} CVEs from NVD.")
            # Prioritize CVEs by base score
            nvd_findings.sort(
                key=lambda x: x.get(
                    'cvss_score', 0), reverse=True)
            highest_cve = nvd_findings[0]
            summary_parts.append(
                f"Highest severity CVE: {highest_cve.get('id')} (Score: {highest_cve.get('cvss_score')}")

        if github_findings:
            summary_parts.append(
                f"Found {len(github_findings)} potential exploits on GitHub.")
            # Prioritize exploits by stars or forks as a proxy for quality
            github_findings.sort(
                key=lambda x: x.get(
                    'stargazers_count',
                    0),
                reverse=True)
            best_exploit = github_findings[0]
            summary_parts.append(
                f"Top exploit candidate from GitHub: {best_exploit.get('html_url', 'N/A')} (Stars: {best_exploit.get('stargazers_count')} for repo {best_exploit.get('full_name')}.")

        if exploitdb_findings:
            summary_parts.append(
                f"Found {len(exploitdb_findings)} potential exploits on Exploit-DB.")
            # This is a placeholder for Exploit-DB correlation.

        if packetstorm_findings:
            summary_parts.append(
                f"Found {len(packetstorm_findings)} potential exploits on Packet Storm.")
            # This is a placeholder for Packet Storm correlation.

        if not best_exploit and nvd_findings:
            summary_parts.append(
                "No direct exploit PoCs found, but CVEs exist.")

        return " ".join(summary_parts), best_exploit
